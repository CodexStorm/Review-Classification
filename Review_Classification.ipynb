{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDgby9iIL85w"
   },
   "source": [
    "# Review Classification\n",
    "\n",
    "The goal of this project is to build a classifier which determines whether a given review is spam or non-spam. The dataset contains truthful and deceptive (spam) reviews for hotels. This includes initializing the data, data pre-processing, feature-selection, creating visualizations, creating models, and measuring their performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGRTcRXPNiwT"
   },
   "source": [
    "This coding segment will handle any imports that we will use for the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bSznGRoGNikz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import metrics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7Bw8ahCM5U_"
   },
   "source": [
    "# **Loading of Data**\n",
    "\n",
    "The following code segment will handle loading in the data and setting the feature target values as the data is given to us as text files and are indicated as spam either by the file name or the folder name. To load the data, please righr click on the sample_data file folder and choose upload. Then upload the negative_polarity and positive_polarity folders from the project dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zok8AA-mfpk"
   },
   "source": [
    "Beware that this segment can take 10+ mins to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "JJ2YBS_sToaZ",
    "outputId": "9a4940a3-001e-4d22-9e81-8151403874a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>hotel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d_talbott_9.txt</td>\n",
       "      <td>The Talbott Hotel claims to be Chicago's Premi...</td>\n",
       "      <td>1</td>\n",
       "      <td>talbott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d_talbott_8.txt</td>\n",
       "      <td>I selected The Talbott for my recent family va...</td>\n",
       "      <td>1</td>\n",
       "      <td>talbott</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d_affinia_20.txt</td>\n",
       "      <td>I recently stayed at the Affinia Hotel in Chic...</td>\n",
       "      <td>1</td>\n",
       "      <td>affinia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d_hardrock_18.txt</td>\n",
       "      <td>My husband and I stayed here at the Hard Rock ...</td>\n",
       "      <td>1</td>\n",
       "      <td>hardrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d_hardrock_19.txt</td>\n",
       "      <td>I stayed at the Hard Rock Hotel in Chicago rec...</td>\n",
       "      <td>1</td>\n",
       "      <td>hardrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>t_james_18.txt</td>\n",
       "      <td>My significant other and I recently spent 3 ni...</td>\n",
       "      <td>0</td>\n",
       "      <td>james</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>t_monaco_1.txt</td>\n",
       "      <td>This is a great hotel! From the doorman who gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>monaco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>t_james_19.txt</td>\n",
       "      <td>I believe I can not describe how amazing was o...</td>\n",
       "      <td>0</td>\n",
       "      <td>james</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>t_monaco_3.txt</td>\n",
       "      <td>Stayed at the Monaco for a romantic weekend ge...</td>\n",
       "      <td>0</td>\n",
       "      <td>monaco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>t_monaco_2.txt</td>\n",
       "      <td>Our room was on the third floor so there was s...</td>\n",
       "      <td>0</td>\n",
       "      <td>monaco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              file_name                                               text  \\\n",
       "0       d_talbott_9.txt  The Talbott Hotel claims to be Chicago's Premi...   \n",
       "1       d_talbott_8.txt  I selected The Talbott for my recent family va...   \n",
       "2      d_affinia_20.txt  I recently stayed at the Affinia Hotel in Chic...   \n",
       "3     d_hardrock_18.txt  My husband and I stayed here at the Hard Rock ...   \n",
       "4     d_hardrock_19.txt  I stayed at the Hard Rock Hotel in Chicago rec...   \n",
       "...                 ...                                                ...   \n",
       "1595     t_james_18.txt  My significant other and I recently spent 3 ni...   \n",
       "1596     t_monaco_1.txt  This is a great hotel! From the doorman who gr...   \n",
       "1597     t_james_19.txt  I believe I can not describe how amazing was o...   \n",
       "1598     t_monaco_3.txt  Stayed at the Monaco for a romantic weekend ge...   \n",
       "1599     t_monaco_2.txt  Our room was on the third floor so there was s...   \n",
       "\n",
       "      target     hotel  \n",
       "0          1   talbott  \n",
       "1          1   talbott  \n",
       "2          1   affinia  \n",
       "3          1  hardrock  \n",
       "4          1  hardrock  \n",
       "...      ...       ...  \n",
       "1595       0     james  \n",
       "1596       0    monaco  \n",
       "1597       0     james  \n",
       "1598       0    monaco  \n",
       "1599       0    monaco  \n",
       "\n",
       "[1600 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required module\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def getFiles(path, target, temp):\n",
    "    for dir in os.listdir(path):\n",
    "        for files in os.listdir(path + dir):\n",
    "            with open(path + dir + \"/\" + files, \"r\") as file_open:\n",
    "                temp[\"file_name\"].append(files)\n",
    "                temp[\"text\"].append(file_open.read())\n",
    "                temp[\"target\"].append(target)\n",
    "                temp[\"hotel\"].append(files.split('_')[1])\n",
    "    return temp\n",
    "\n",
    "\n",
    "results = defaultdict(list)\n",
    "\n",
    "path = 'data/negative_polarity/deceptive_from_MTurk/'\n",
    "\n",
    "getFiles(path, 1, results)\n",
    "\n",
    "path = 'data/negative_polarity/truthful_from_Web/'\n",
    "\n",
    "getFiles(path, 0, results)\n",
    "\n",
    "path = 'data/positive_polarity/deceptive_from_MTurk/'\n",
    "\n",
    "getFiles(path, 1, results)\n",
    "\n",
    "path = 'data/positive_polarity/truthful_from_TripAdvisor/'\n",
    "\n",
    "getFiles(path, 0, results)\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7zm_HQeTarkv",
    "outputId": "d1479f4e-64c0-46a2-d3ad-42e6d7ece4b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    800\n",
       "0    800\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGYsEg8SYVPY"
   },
   "source": [
    "# **Data Preprocessing**\n",
    "\n",
    "Data preprocessing is a crucial stage in Machine Learning because the quality of data and the relevant information that can be extracted from it has a direct impact on our model's capacity to learn. Therefore, preprocessing our data before feeding it into our model is critical.\n",
    "\n",
    "## **Get list of most commonly used words**\n",
    "\n",
    "After preprocessing the reviews, we have a list of words for each review. The next step we choose which words we would like to use in our classifier and which we would want to leave out. For this, we have chosen only the most frequently occuring words as our set of words considered (the vocabulary list. The complete vocabulary list is in the file vocab.txt. Given the vocabulary list, we can now map each word in the preprocessed emails into a list of word indices that contains the index of the word in the vocabulary list. In the code, we are giving a string str which is a single word from the processed review. We then look up the word in the vocabulary list vocabList and find if the word exists in the vocabulary list. If the word exists, we then add the index of the word into the word indices variable. If the word does not exist, and is therefore not in the vocabulary, we skip the word. The code below will load the vocab.txt file to get list of most frequently used words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ycb5iZEOeEqo"
   },
   "outputs": [],
   "source": [
    "# To get the list of words from the text file vocab.txt\n",
    "def getVocabList():\n",
    "  \n",
    "  # Reading the txt file\n",
    "    data = pd.read_csv(\"vocab.txt\", sep='\\t')\n",
    "\n",
    "    words = []\n",
    "\n",
    "  # Appending the words to create the final list\n",
    "    for index, row in data.iterrows():\n",
    "        words.append(row[\"aa\"])\n",
    "  \n",
    "  # Returning the final set of words\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cf_rjPzrarC9"
   },
   "source": [
    "## Preprocessing of Reviews\n",
    "\n",
    "We follow the below steps to preprocess reviews\n",
    "\n",
    "*  **Lower-casing:** The entire review is converted into lower case, so that captialization is ignored (e.g., IndIcaTE is treated the same as indicate)\n",
    "*  **Stripping HTML:** All HTML tags are removed from the reviews. Many reviews often come with HTML formatting. We remove all the HTML tags, so that only the content remains.\n",
    "*  **Normalizing URLs:** All URLs are replaced with the text \"httpaddr\".\n",
    "*  **Normalizing Email Addresses:** All email addresses are replaced with the text \"emailaddr\".\n",
    "*  **Normalizing Numbers:** All numbers are replaced with the text 'number'.\n",
    "*  **Normalizing Dollars:** All dollar signs ($) are replaced with the text 'dollar'.\n",
    "*  **Word Stemming:** Words are reduced to their stemmed form. For example, 'discount', 'discounts', 'discounted' and 'discounting' are all replaced with 'discount'. Sometimes, the Stemmer actually strips off additional characters from the end, so 'include', 'includes', 'included', and 'including' are all replaced with 'includ'.\n",
    "*  **Removal of non-words:** Non-words and punctuation have been removed. All white spaces (tabs, newlines, spaces) have all been trimmed to a single space character.\n",
    "\n",
    "The function below does the preprocessing of a review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kPYglsbxISc8"
   },
   "outputs": [],
   "source": [
    "def processReviews(review):\n",
    "\n",
    "    wordList = getVocabList()\n",
    "\n",
    "    wordIndices = []\n",
    "\n",
    "  # To convert all the characters to lower case\n",
    "    review = review.lower()\n",
    "\n",
    "  # To remove HTML tags\n",
    "    review = re.sub('<[^<>]+>', '', review)\n",
    "\n",
    "  # To handle number\n",
    "    review = re.sub('[0-9]+', 'number', review)\n",
    "\n",
    "  # To handle URLS\n",
    "    review = re.sub('(http|https)://[^\\s]*', 'httpaddr', review)\n",
    "\n",
    "  # To handle Email Address\n",
    "    review = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', review)\n",
    "\n",
    "  # To handle $ sign\n",
    "    review = re.sub('[$]+', 'dollar', review)\n",
    "  \n",
    "    words = review.split(\" \")\n",
    "\n",
    "    review = []\n",
    "\n",
    "    for word in words:\n",
    "\n",
    "    # To remove non alphabatic characters, like punctation\n",
    "        word = re.sub('[^a-zA-Z0-9]', '', word)\n",
    "\n",
    "    # Stemming\n",
    "        porter = PorterStemmer()\n",
    "        word = porter.stem(word)\n",
    "\n",
    "        if len(word) < 1:\n",
    "            continue\n",
    "      \n",
    "    # To create list of index\n",
    "        for index,vocab in enumerate(wordList):\n",
    "            if(word == vocab):\n",
    "                review.append(str(index))\n",
    "\n",
    "        review = \" \".join(review)\n",
    "\n",
    "    return review\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "hAY_4LkrzT31",
    "outputId": "82ef3979-1f99-4504-b8bc-2e37933bec02"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'1082 1084 875 1728 1728 1728 1118 797 529 477'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example\n",
    "processReviews(\"My name is Manoj! trouble troubling troubled <Home><\\Home> 12 https://www.google.com/ manojkar@uw.edu $12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PqfU-1wkuZW"
   },
   "source": [
    "This code segment also takes some time to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 943
    },
    "id": "Gq37DASc88n5",
    "outputId": "6fdd9ffb-07ac-4240-a0e1-00bc8df6458d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>hotel</th>\n",
       "      <th>pre_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d_knickerbocker_4.txt</td>\n",
       "      <td>While the hotel certainly seems to look beauti...</td>\n",
       "      <td>1</td>\n",
       "      <td>knickerbocker</td>\n",
       "      <td>1839 1664 266 1469 1697 974 1664 875 18 614 68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d_sheraton_2.txt</td>\n",
       "      <td>The Sheraton Chicago Hotel and Towers is not t...</td>\n",
       "      <td>1</td>\n",
       "      <td>sheraton</td>\n",
       "      <td>1664 72 875 1111 1664 664 1240 1857 1697 754 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d_knickerbocker_10.txt</td>\n",
       "      <td>After a my stay at the Millennium Knickerbocke...</td>\n",
       "      <td>1</td>\n",
       "      <td>knickerbocker</td>\n",
       "      <td>37 1082 122 1664 1664 1664 1271 1345 1160 1082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d_homewood_17.txt</td>\n",
       "      <td>Whatever you do, do NOT stay at the Homewood S...</td>\n",
       "      <td>1</td>\n",
       "      <td>homewood</td>\n",
       "      <td>1834 1891 469 469 1111 122 1664 1614 823 987 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d_knickerbocker_6.txt</td>\n",
       "      <td>The Millennium Knickerbocker Hotel has seen be...</td>\n",
       "      <td>1</td>\n",
       "      <td>knickerbocker</td>\n",
       "      <td>1664 741 1470 176 743 1025 1160 1671 1835 881 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>t_amalfi_1.txt</td>\n",
       "      <td>This hotel cannot be beat for location, price,...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1674 238 160 161 664 968 1297 1664 968 875 122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>t_amalfi_4.txt</td>\n",
       "      <td>We stayed for just one night ,but the hotel st...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1817 664 900 1103 223 1664 1577 1801 602 72 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>t_amalfi_6.txt</td>\n",
       "      <td>I would definitely recommend this hotel to any...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1874 419 1374 1674 1697 84 1807 823 1276 979 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>t_amalfi_18.txt</td>\n",
       "      <td>Review's a little late, but... My husband &amp; I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1419 961 927 223 1082 650 122 1664 823 1711 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>t_amalfi_11.txt</td>\n",
       "      <td>We attended a Bachorette Party in Chicago in A...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1817 1211 823 823 131 1118 1671 1831 1118 709 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name  ...                                           pre_text\n",
       "0      d_knickerbocker_4.txt  ...  1839 1664 266 1469 1697 974 1664 875 18 614 68...\n",
       "1           d_sheraton_2.txt  ...  1664 72 875 1111 1664 664 1240 1857 1697 754 1...\n",
       "2     d_knickerbocker_10.txt  ...  37 1082 122 1664 1664 1664 1271 1345 1160 1082...\n",
       "3          d_homewood_17.txt  ...  1834 1891 469 469 1111 122 1664 1614 823 987 1...\n",
       "4      d_knickerbocker_6.txt  ...  1664 741 1470 176 743 1025 1160 1671 1835 881 ...\n",
       "...                      ...  ...                                                ...\n",
       "1595          t_amalfi_1.txt  ...  1674 238 160 161 664 968 1297 1664 968 875 122...\n",
       "1596          t_amalfi_4.txt  ...  1817 664 900 1103 223 1664 1577 1801 602 72 12...\n",
       "1597          t_amalfi_6.txt  ...  1874 419 1374 1674 1697 84 1807 823 1276 979 1...\n",
       "1598         t_amalfi_18.txt  ...  1419 961 927 223 1082 650 122 1664 823 1711 15...\n",
       "1599         t_amalfi_11.txt  ...  1817 1211 823 823 131 1118 1671 1831 1118 709 ...\n",
       "\n",
       "[1600 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pre_text\"] = df[\"text\"].apply(lambda x: processReviews(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9d8H49TWFXAE"
   },
   "outputs": [],
   "source": [
    "def getAVG(vals):\n",
    "  nums = [int(x) for x in vals.split(' ')]\n",
    "  count = 0\n",
    "  for num in nums:\n",
    "    count = count + num\n",
    "  return count / len(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqjYeCmfGjwQ",
    "outputId": "3715799c-818e-4638-f77c-72a7ba286e2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114.6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example\n",
    "getAVG(processReviews(\"My name is Manoj! trouble troubling troubled <Home><\\Home> 12 https://www.google.com/ manojkar@uw.edu $12\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFUITrB6mrG1"
   },
   "source": [
    "# **Data Visualization**\n",
    "\n",
    "Here we are looking at some of the data features. As you can see, there are not many visual differences between the truthful and deceitful data. This makes sense as the goal of deceitful data is to look as similar to truthful data as possible. If there were easy to spot visual differnces, the problem of finding opinion spam would be trivial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VTdl0NuoHCDc",
    "outputId": "5aa8627e-d26d-4aba-be85-ffde24b2a587"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>hotel</th>\n",
       "      <th>pre_text</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d_knickerbocker_4.txt</td>\n",
       "      <td>While the hotel certainly seems to look beauti...</td>\n",
       "      <td>1</td>\n",
       "      <td>knickerbocker</td>\n",
       "      <td>1839 1664 266 1469 1697 974 1664 875 18 614 68...</td>\n",
       "      <td>879.510204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d_sheraton_2.txt</td>\n",
       "      <td>The Sheraton Chicago Hotel and Towers is not t...</td>\n",
       "      <td>1</td>\n",
       "      <td>sheraton</td>\n",
       "      <td>1664 72 875 1111 1664 664 1240 1857 1697 754 1...</td>\n",
       "      <td>1159.344828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d_knickerbocker_10.txt</td>\n",
       "      <td>After a my stay at the Millennium Knickerbocke...</td>\n",
       "      <td>1</td>\n",
       "      <td>knickerbocker</td>\n",
       "      <td>37 1082 122 1664 1664 1664 1271 1345 1160 1082...</td>\n",
       "      <td>1126.664234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d_homewood_17.txt</td>\n",
       "      <td>Whatever you do, do NOT stay at the Homewood S...</td>\n",
       "      <td>1</td>\n",
       "      <td>homewood</td>\n",
       "      <td>1834 1891 469 469 1111 122 1664 1614 823 987 1...</td>\n",
       "      <td>1018.008621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d_knickerbocker_6.txt</td>\n",
       "      <td>The Millennium Knickerbocker Hotel has seen be...</td>\n",
       "      <td>1</td>\n",
       "      <td>knickerbocker</td>\n",
       "      <td>1664 741 1470 176 743 1025 1160 1671 1835 881 ...</td>\n",
       "      <td>1092.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>t_amalfi_1.txt</td>\n",
       "      <td>This hotel cannot be beat for location, price,...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1674 238 160 161 664 968 1297 1664 968 875 122...</td>\n",
       "      <td>1039.163462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>t_amalfi_4.txt</td>\n",
       "      <td>We stayed for just one night ,but the hotel st...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1817 664 900 1103 223 1664 1577 1801 602 72 12...</td>\n",
       "      <td>970.962963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>t_amalfi_6.txt</td>\n",
       "      <td>I would definitely recommend this hotel to any...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1874 419 1374 1674 1697 84 1807 823 1276 979 1...</td>\n",
       "      <td>1200.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>t_amalfi_18.txt</td>\n",
       "      <td>Review's a little late, but... My husband &amp; I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1419 961 927 223 1082 650 122 1664 823 1711 15...</td>\n",
       "      <td>1169.264706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>t_amalfi_11.txt</td>\n",
       "      <td>We attended a Bachorette Party in Chicago in A...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1817 1211 823 823 131 1118 1671 1831 1118 709 ...</td>\n",
       "      <td>1039.281818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name  ...      average\n",
       "0      d_knickerbocker_4.txt  ...   879.510204\n",
       "1           d_sheraton_2.txt  ...  1159.344828\n",
       "2     d_knickerbocker_10.txt  ...  1126.664234\n",
       "3          d_homewood_17.txt  ...  1018.008621\n",
       "4      d_knickerbocker_6.txt  ...  1092.000000\n",
       "...                      ...  ...          ...\n",
       "1595          t_amalfi_1.txt  ...  1039.163462\n",
       "1596          t_amalfi_4.txt  ...   970.962963\n",
       "1597          t_amalfi_6.txt  ...  1200.117647\n",
       "1598         t_amalfi_18.txt  ...  1169.264706\n",
       "1599         t_amalfi_11.txt  ...  1039.281818\n",
       "\n",
       "[1600 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"average\"] = df[\"pre_text\"].apply(lambda x: getAVG(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "VbKVJtMOIAVO",
    "outputId": "604225d8-030a-458e-e00a-89c7007c79d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1093.789130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1095.710043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target      average\n",
       "0       0  1093.789130\n",
       "1       1  1095.710043"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('target', as_index=False)['average'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EAUpdCugI50-"
   },
   "outputs": [],
   "source": [
    "def preprocess(ReviewText):\n",
    "    ReviewText = ReviewText.str.replace(\"(<br/>)\", \"\")\n",
    "    ReviewText = ReviewText.str.replace('(<a).*(>).*(</a>)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&amp)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&gt)', '')\n",
    "    ReviewText = ReviewText.str.replace('(&lt)', '')\n",
    "    ReviewText = ReviewText.str.replace('(\\xa0)', ' ')  \n",
    "    return ReviewText\n",
    "df['Review Text'] = preprocess(df['text'])\n",
    "\n",
    "df['polarity'] = df['Review Text'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "df['review_len'] = df['Review Text'].astype(str).apply(len)\n",
    "df['word_count'] = df['Review Text'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TU376k0fJGav",
    "outputId": "e39b9f7b-1e3a-4480-d8b5-a78e1b8175d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>hotel</th>\n",
       "      <th>pre_text</th>\n",
       "      <th>average</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>review_len</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d_knickerbocker_4.txt</td>\n",
       "      <td>While the hotel certainly seems to look beauti...</td>\n",
       "      <td>1</td>\n",
       "      <td>knickerbocker</td>\n",
       "      <td>1839 1664 266 1469 1697 974 1664 875 18 614 68...</td>\n",
       "      <td>879.510204</td>\n",
       "      <td>While the hotel certainly seems to look beauti...</td>\n",
       "      <td>0.073469</td>\n",
       "      <td>341</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d_sheraton_2.txt</td>\n",
       "      <td>The Sheraton Chicago Hotel and Towers is not t...</td>\n",
       "      <td>1</td>\n",
       "      <td>sheraton</td>\n",
       "      <td>1664 72 875 1111 1664 664 1240 1857 1697 754 1...</td>\n",
       "      <td>1159.344828</td>\n",
       "      <td>The Sheraton Chicago Hotel and Towers is not t...</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>874</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d_knickerbocker_10.txt</td>\n",
       "      <td>After a my stay at the Millennium Knickerbocke...</td>\n",
       "      <td>1</td>\n",
       "      <td>knickerbocker</td>\n",
       "      <td>37 1082 122 1664 1664 1664 1271 1345 1160 1082...</td>\n",
       "      <td>1126.664234</td>\n",
       "      <td>After a my stay at the Millennium Knickerbocke...</td>\n",
       "      <td>-0.069643</td>\n",
       "      <td>985</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d_homewood_17.txt</td>\n",
       "      <td>Whatever you do, do NOT stay at the Homewood S...</td>\n",
       "      <td>1</td>\n",
       "      <td>homewood</td>\n",
       "      <td>1834 1891 469 469 1111 122 1664 1614 823 987 1...</td>\n",
       "      <td>1018.008621</td>\n",
       "      <td>Whatever you do, do NOT stay at the Homewood S...</td>\n",
       "      <td>-0.116592</td>\n",
       "      <td>880</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d_knickerbocker_6.txt</td>\n",
       "      <td>The Millennium Knickerbocker Hotel has seen be...</td>\n",
       "      <td>1</td>\n",
       "      <td>knickerbocker</td>\n",
       "      <td>1664 741 1470 176 743 1025 1160 1671 1835 881 ...</td>\n",
       "      <td>1092.000000</td>\n",
       "      <td>The Millennium Knickerbocker Hotel has seen be...</td>\n",
       "      <td>0.177646</td>\n",
       "      <td>817</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>t_amalfi_1.txt</td>\n",
       "      <td>This hotel cannot be beat for location, price,...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1674 238 160 161 664 968 1297 1664 968 875 122...</td>\n",
       "      <td>1039.163462</td>\n",
       "      <td>This hotel cannot be beat for location, price,...</td>\n",
       "      <td>0.380455</td>\n",
       "      <td>841</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>t_amalfi_4.txt</td>\n",
       "      <td>We stayed for just one night ,but the hotel st...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1817 664 900 1103 223 1664 1577 1801 602 72 12...</td>\n",
       "      <td>970.962963</td>\n",
       "      <td>We stayed for just one night ,but the hotel st...</td>\n",
       "      <td>0.505595</td>\n",
       "      <td>391</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>t_amalfi_6.txt</td>\n",
       "      <td>I would definitely recommend this hotel to any...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1874 419 1374 1674 1697 84 1807 823 1276 979 1...</td>\n",
       "      <td>1200.117647</td>\n",
       "      <td>I would definitely recommend this hotel to any...</td>\n",
       "      <td>0.391981</td>\n",
       "      <td>487</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>t_amalfi_18.txt</td>\n",
       "      <td>Review's a little late, but... My husband &amp; I ...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1419 961 927 223 1082 650 122 1664 823 1711 15...</td>\n",
       "      <td>1169.264706</td>\n",
       "      <td>Review's a little late, but... My husband &amp; I ...</td>\n",
       "      <td>0.273958</td>\n",
       "      <td>525</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>t_amalfi_11.txt</td>\n",
       "      <td>We attended a Bachorette Party in Chicago in A...</td>\n",
       "      <td>0</td>\n",
       "      <td>amalfi</td>\n",
       "      <td>1817 1211 823 823 131 1118 1671 1831 1118 709 ...</td>\n",
       "      <td>1039.281818</td>\n",
       "      <td>We attended a Bachorette Party in Chicago in A...</td>\n",
       "      <td>0.369444</td>\n",
       "      <td>735</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name  ... word_count\n",
       "0      d_knickerbocker_4.txt  ...         61\n",
       "1           d_sheraton_2.txt  ...        150\n",
       "2     d_knickerbocker_10.txt  ...        186\n",
       "3          d_homewood_17.txt  ...        162\n",
       "4      d_knickerbocker_6.txt  ...        148\n",
       "...                      ...  ...        ...\n",
       "1595          t_amalfi_1.txt  ...        149\n",
       "1596          t_amalfi_4.txt  ...         68\n",
       "1597          t_amalfi_6.txt  ...         75\n",
       "1598         t_amalfi_18.txt  ...         97\n",
       "1599         t_amalfi_11.txt  ...        139\n",
       "\n",
       "[1600 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "LICSK8XmJtAy",
    "outputId": "7e88123c-09f0-4cce-9c6d-c61fca3bc7ce"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>review_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>821.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>791.7675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  review_len\n",
       "0       0    821.0150\n",
       "1       1    791.7675"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('target', as_index=False)['review_len'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "AbQhHhLQJyBO",
    "outputId": "c64a765b-eb62-4c88-f62e-2c0bf1ea84dc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>150.91375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>146.63625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  word_count\n",
       "0       0   150.91375\n",
       "1       1   146.63625"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('target', as_index=False)['word_count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "l8IYtJqDJ4G_",
    "outputId": "30c1c280-e6e8-4e68-9d63-05f79d76243d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.203070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.196947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  polarity\n",
       "0       0  0.203070\n",
       "1       1  0.196947"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('target', as_index=False)['polarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "LAUQwBVVKSHH",
    "outputId": "c27dda87-34de-46ba-c912-1bcbcadc23ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel</th>\n",
       "      <th>target</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>affinia</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>affinia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>allegro</td>\n",
       "      <td>0</td>\n",
       "      <td>0.162500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>allegro</td>\n",
       "      <td>1</td>\n",
       "      <td>0.178766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amalfi</td>\n",
       "      <td>0</td>\n",
       "      <td>0.221881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amalfi</td>\n",
       "      <td>1</td>\n",
       "      <td>0.236164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ambassador</td>\n",
       "      <td>0</td>\n",
       "      <td>0.209726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ambassador</td>\n",
       "      <td>1</td>\n",
       "      <td>0.176530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>conrad</td>\n",
       "      <td>0</td>\n",
       "      <td>0.218139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>conrad</td>\n",
       "      <td>1</td>\n",
       "      <td>0.199004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fairmont</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>fairmont</td>\n",
       "      <td>1</td>\n",
       "      <td>0.165128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hardrock</td>\n",
       "      <td>0</td>\n",
       "      <td>0.192626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>hardrock</td>\n",
       "      <td>1</td>\n",
       "      <td>0.138811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>hilton</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hilton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.183189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>homewood</td>\n",
       "      <td>0</td>\n",
       "      <td>0.223735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>homewood</td>\n",
       "      <td>1</td>\n",
       "      <td>0.171835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hyatt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hyatt</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>intercontinental</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>intercontinental</td>\n",
       "      <td>1</td>\n",
       "      <td>0.209001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>james</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>james</td>\n",
       "      <td>1</td>\n",
       "      <td>0.221291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>knickerbocker</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>knickerbocker</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>monaco</td>\n",
       "      <td>0</td>\n",
       "      <td>0.247769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>monaco</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>omni</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>omni</td>\n",
       "      <td>1</td>\n",
       "      <td>0.182455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>palmer</td>\n",
       "      <td>0</td>\n",
       "      <td>0.190583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>palmer</td>\n",
       "      <td>1</td>\n",
       "      <td>0.234370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>sheraton</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>sheraton</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sofitel</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>sofitel</td>\n",
       "      <td>1</td>\n",
       "      <td>0.210362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>swissotel</td>\n",
       "      <td>0</td>\n",
       "      <td>0.200053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>swissotel</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>talbott</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>talbott</td>\n",
       "      <td>1</td>\n",
       "      <td>0.179730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               hotel  target  polarity\n",
       "0            affinia       0  0.175145\n",
       "1            affinia       1  0.230267\n",
       "2            allegro       0  0.162500\n",
       "3            allegro       1  0.178766\n",
       "4             amalfi       0  0.221881\n",
       "5             amalfi       1  0.236164\n",
       "6         ambassador       0  0.209726\n",
       "7         ambassador       1  0.176530\n",
       "8             conrad       0  0.218139\n",
       "9             conrad       1  0.199004\n",
       "10          fairmont       0  0.177744\n",
       "11          fairmont       1  0.165128\n",
       "12          hardrock       0  0.192626\n",
       "13          hardrock       1  0.138811\n",
       "14            hilton       0  0.196053\n",
       "15            hilton       1  0.183189\n",
       "16          homewood       0  0.223735\n",
       "17          homewood       1  0.171835\n",
       "18             hyatt       0  0.181287\n",
       "19             hyatt       1  0.215254\n",
       "20  intercontinental       0  0.228113\n",
       "21  intercontinental       1  0.209001\n",
       "22             james       0  0.196323\n",
       "23             james       1  0.221291\n",
       "24     knickerbocker       0  0.174236\n",
       "25     knickerbocker       1  0.196950\n",
       "26            monaco       0  0.247769\n",
       "27            monaco       1  0.196086\n",
       "28              omni       0  0.228833\n",
       "29              omni       1  0.182455\n",
       "30            palmer       0  0.190583\n",
       "31            palmer       1  0.234370\n",
       "32          sheraton       0  0.196950\n",
       "33          sheraton       1  0.217710\n",
       "34           sofitel       0  0.271521\n",
       "35           sofitel       1  0.210362\n",
       "36         swissotel       0  0.200053\n",
       "37         swissotel       1  0.196029\n",
       "38           talbott       0  0.168189\n",
       "39           talbott       1  0.179730"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['hotel', 'target'], as_index=False)['polarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "KbQu3BfL8o7j",
    "outputId": "39961d74-9f4f-4a3f-fb2d-9c157affbe80"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(['True', 'Deceptive'], df.groupby('target', as_index=False)['review_len'].mean()['review_len'])\n",
    "plt.title(\"Truthfulness vs. Review Length\")\n",
    "plt.xlabel(\"Truthfulness\")\n",
    "plt.ylabel(\"Average review length\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfE44fnmmy2k"
   },
   "source": [
    "# Testing Splits\n",
    "\n",
    "This is where we will split the data into our testing and training splits. As you can see from the code, we have decided to follow convention and train using %80 of the data and test using the other %20. Before we handle the data, we create 3 separate copies for each of us to use to ensure that each model uses fresh data that hasn't been modified more than it has been already up to this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGg5M4klaG-n",
    "outputId": "ce05c920-97e7-42c0-ff41-14883c99de82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1504    The Sheraton is a fantastic hotel. My wife and...\n",
       "107     I stayed here last August and I'm truly glad t...\n",
       "84      When I went to The James hotel in Chicago I tr...\n",
       "385     I will never stay at Conrad Chicago again. The...\n",
       "780     We recently stayed at the hotel allegro in chi...\n",
       "                              ...                        \n",
       "1474    I loved this hotel - fabulous old building but...\n",
       "469     Under the gloss of a nice building, friendly s...\n",
       "284     We originally made reservations for a weekend ...\n",
       "218     This hotel is ok but is not the best for the m...\n",
       "1215    Just putting in a good word for the Hard Rock ...\n",
       "Name: Review Text, Length: 320, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting based on our chosen feature to train with.\n",
    "X = df[\"Review Text\"]\n",
    "y = df[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=115)\n",
    "\n",
    "SVM_X_train = X_train\n",
    "MLP_X_train = X_train\n",
    "DTC_X_train = X_train\n",
    "\n",
    "SVM_X_test = X_test\n",
    "MLP_X_test = X_test\n",
    "DTC_X_test = X_test\n",
    "\n",
    "SVM_y_train = y_train\n",
    "MLP_y_train = y_train\n",
    "DTC_y_train = y_train\n",
    "\n",
    "SVM_y_test = y_test\n",
    "MLP_y_test = y_test\n",
    "DTC_y_test = y_test\n",
    "\n",
    "MLP_X_test\n",
    "DTC_X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MAO7i22BKsZ"
   },
   "source": [
    "# MLP Classifier\n",
    "\n",
    "For the first of our chosen models, we have decided to create a MLP or a multi-layer perceptron model. The goal of this model is to optimize its given loss model and backpropagates accordingly based on the output. We stick fairly close to defualt for the parameters for reasons that will be mentioned later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E95yBtPh1BrQ",
    "outputId": "269e04bb-83b9-40d6-bb95-9e51530c8821"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1280x8510 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 116457 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "MLP_X_train = vectorizer.fit_transform(MLP_X_train)\n",
    "MLP_X_test = vectorizer.transform(MLP_X_test)\n",
    "vectorizer.get_feature_names_out()\n",
    "MLP_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zjk7PX3afAer"
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(random_state=1, max_iter=200).fit(MLP_X_train, MLP_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iekW7Vi92NBN",
    "outputId": "b2dc34d5-a083-4196-b79d-d1cb42f20d80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<320x8510 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 28906 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lgbjUjeBCoNx",
    "outputId": "091d92db-fb1d-4452-9e76-297628ca321e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "MLP: 0.8875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       171\n",
      "           1       0.88      0.88      0.88       149\n",
      "\n",
      "    accuracy                           0.89       320\n",
      "   macro avg       0.89      0.89      0.89       320\n",
      "weighted avg       0.89      0.89      0.89       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_predict = mlp.predict(MLP_X_test)\n",
    "mlp_predict\n",
    "print('Accuracy:\\n' + 'MLP: ' + str(accuracy_score(MLP_y_test, mlp_predict)))\n",
    "print(metrics.classification_report(MLP_y_test, mlp_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3HP9FLCp_82"
   },
   "source": [
    "## Parameter Tuning\n",
    "\n",
    "I originally planned on parameter tuning, but running the GridSearchCV sklearn package on my code took +1hr each time and yielded negligible improvements to the accuracy so I decided to stick with the default classifier with max_iter bumped up to 300 instead of the default 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mPRQkLKBClG"
   },
   "source": [
    "# SVM Classifier\n",
    "\n",
    "The \"Support Vector Machine\" (SVM) is a supervised machine learning technique that can solve classification and regression problems. It is, however, mostly employed to solve categorization difficulties. Each data item is plotted as a point in n-dimensional space (where n is the number of features you have), with the value of each feature being the value of a certain coordinate in the SVM algorithm. Then we accomplish classification by locating the hyper-plane that clearly distinguishes the two classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gd5TtViESqB"
   },
   "outputs": [],
   "source": [
    "# Implementing Vectoriser\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "SVM_X_train_v = vectorizer.fit_transform(SVM_X_train)\n",
    "SVM_X_test_v = vectorizer.transform(SVM_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jd-DM18LDDZE",
    "outputId": "690f0789-d962-4a92-c8d8-7742f1c89acd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM Model\n",
    "\n",
    "svm_model = svm.SVC(kernel='linear')\n",
    "svm_model.fit(SVM_X_train_v, SVM_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "siek9oY0Du18",
    "outputId": "6f8948d0-9ec9-4b29-e0e8-ada0ef8846a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.87       171\n",
      "           1       0.84      0.89      0.86       149\n",
      "\n",
      "    accuracy                           0.87       320\n",
      "   macro avg       0.87      0.87      0.87       320\n",
      "weighted avg       0.87      0.87      0.87       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "SVM_pred_test = svm_model.predict(SVM_X_test_v)\n",
    "print(classification_report(SVM_y_test, SVM_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEk4RNPEkxkd"
   },
   "source": [
    "## **Paramatter Tuning**\n",
    "\n",
    "Hyper-parameters are variables that aren't learned directly by estimators. They are supplied as inputs to the constructor of the estimator classes in scikit-learn. Grid search is a technique of hyper-parameter tuning that builds and evaluates a model systematically for each combination of algorithm parameters supplied on a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5vq148QO4I1"
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    " \n",
    "grid = GridSearchCV(svm_model, param_grid, refit = True, verbose = 3)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UfCT91BuRNeI",
    "outputId": "6c90ef9a-e946-44cc-99cb-2ee579e87308"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.512 total time=   1.3s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.512 total time=   1.3s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.512 total time=   1.3s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.512 total time=   1.3s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.512 total time=   1.3s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.875 total time=   1.3s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.871 total time=   1.3s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.863 total time=   1.3s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.891 total time=   1.3s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.902 total time=   1.3s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.836 total time=   1.3s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.824 total time=   1.3s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.828 total time=   1.3s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.875 total time=   1.3s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.879 total time=   1.3s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.512 total time=   1.3s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.512 total time=   1.3s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.512 total time=   1.3s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.871 total time=   1.3s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.879 total time=   1.3s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.867 total time=   1.3s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.910 total time=   1.3s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.895 total time=   1.3s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.871 total time=   1.2s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.863 total time=   1.2s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.852 total time=   1.2s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.895 total time=   1.2s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.891 total time=   1.2s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.844 total time=   1.2s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.836 total time=   1.2s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.836 total time=   1.2s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.879 total time=   1.3s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.895 total time=   1.3s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.512 total time=   1.3s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.512 total time=   1.3s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.871 total time=   1.3s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.879 total time=   1.3s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.867 total time=   1.3s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.910 total time=   1.3s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.895 total time=   1.3s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.867 total time=   1.2s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.855 total time=   1.2s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.840 total time=   1.2s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.895 total time=   1.2s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.887 total time=   1.2s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.863 total time=   1.1s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.859 total time=   1.2s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.836 total time=   1.1s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.887 total time=   1.2s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.891 total time=   1.1s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.848 total time=   1.2s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.840 total time=   1.2s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.836 total time=   1.2s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.879 total time=   1.2s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.895 total time=   1.2s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.508 total time=   1.3s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.512 total time=   1.3s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.871 total time=   1.3s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.879 total time=   1.3s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.867 total time=   1.3s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.910 total time=   1.3s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.895 total time=   1.3s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.867 total time=   1.2s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.855 total time=   1.2s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.840 total time=   1.2s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.895 total time=   1.2s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.887 total time=   1.2s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.848 total time=   1.2s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.844 total time=   1.2s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.828 total time=   1.2s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.879 total time=   1.2s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.891 total time=   1.2s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.863 total time=   1.1s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.859 total time=   1.2s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.836 total time=   1.1s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.887 total time=   1.1s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.891 total time=   1.2s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.848 total time=   1.2s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.840 total time=   1.2s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.836 total time=   1.2s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.879 total time=   1.3s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.895 total time=   1.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(SVM_X_train_v, SVM_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjg9CIsMRZ7_",
    "outputId": "ec3430d2-c5e0-4bea-f3a2-de1574c08441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "SVC(C=10, gamma=1)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MrL-lkM9SHnP",
    "outputId": "8275a370-cbbf-4503-f505-2939352da566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88       171\n",
      "           1       0.86      0.88      0.87       149\n",
      "\n",
      "    accuracy                           0.88       320\n",
      "   macro avg       0.88      0.88      0.88       320\n",
      "weighted avg       0.88      0.88      0.88       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.predict(SVM_X_test_v)\n",
    "print(classification_report(SVM_y_test, grid_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1ezoBnGYJ4Z"
   },
   "source": [
    "# Decision Trees Classifer\n",
    "A decision tree is a decision support tool that uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. Itâ€™s often implemented to display algorithm that only contains conditional control statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R3hl8nSq3J7H"
   },
   "outputs": [],
   "source": [
    "# Implement Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "DTC_X_train = vectorizer.fit_transform(DTC_X_train)\n",
    "DTC_X_test = vectorizer.transform(DTC_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DDLoKsr3ZvT1",
    "outputId": "27adb736-aa10-4cf2-e029-34c2cd8dd173"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=1279)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Decision Tree Classifier & Train the model using the training sets\n",
    "dtc_model = DecisionTreeClassifier(criterion='gini',max_depth=1279)\n",
    "dtc_model.fit(DTC_X_train, DTC_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19VwUexIg4Qy",
    "outputId": "86d2956b-3f0b-4613-9a0e-9eacd7b0d3ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy using DTC: 0.6375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66       171\n",
      "           1       0.61      0.60      0.61       149\n",
      "\n",
      "    accuracy                           0.64       320\n",
      "   macro avg       0.64      0.63      0.64       320\n",
      "weighted avg       0.64      0.64      0.64       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the response for test dataset\n",
    "dtc_model_pred = dtc_model.predict(DTC_X_test)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Average accuracy using DTC:\",metrics.accuracy_score(DTC_y_test, dtc_model_pred))\n",
    "print(classification_report(DTC_y_test, dtc_model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egqRJZWrbcvM"
   },
   "source": [
    "## Parameter Tuning\n",
    "\n",
    "Considering the iterative and top-down nature of the *decision tree* algorithm, this machine-learning model would be sub-optimal for this Opinion Spamming project unless we implement *random forest*, a combination of several *decision trees*, in order to increase accuracy of the prediction. In other words, a single *decision tree* tends to be over-fitting for the massive amount of data we are processing. Due to the scope of this assignment, we only implemented a single decision tree as a proof-of-concept, but a more elaborative *random forest* would be preferred for later iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0Bp3Kq1B1Rq"
   },
   "source": [
    "# **Related Work**\n",
    "\n",
    "The opinion spam problem is very important because deceitful reviews, both positive and negative can have a large impact on whatever it is they are reviewing. This includes fake reviews drawing customers to a competitor if they are flooded by fake positive reviews or pushing customers away if your own reviews are filled with fake bad reviews. To that end, there are quite a bit of research resources already available on the topic. A paper on **Survey On Opinion Spam Detection Methods** does a great job of summarizing many of these works. In the paper, three approaches to spam detection are introduced, these are detection using review features, reviewer features, and spammer group detection. Our approach falls into the review features as we are looking at each review individually and trying to draw correlations between the reviews. Many of these approaches report similar accuracy results when working with their own data sets, but these tend to struggle when tested on real-world data. Our models would likely follow this trend as well. The other approaches sound very intriguing as well looking at behavioral patterns of review spammers as well as spammer groups in the hopes of pinpointing when they are most active. This only includes a small subset of work on the subject as there are quite a few to begin with.\n",
    "\n",
    "# **Findings**\n",
    "\n",
    "As you can see from the results we have shown, the SVM and MLP models tend to perform better on the data that we have been given. The SVM and MLP models both achieve close to **90%** accuracy on our testing split which is a solid number. The decision tree on the other hand achieves around **70%** accuracy. The reason for this could be that the decision tree is overfit on the training data or possibly there aren't enough features available for the decision tree to be as successful as it can be. \n",
    "\n",
    "# **Conclusion/Future Work**\n",
    "\n",
    "There has been a lot of study on detecting fraudulent and misleading reviews and separating them from genuine, accurate ones. We reviewed the majority of the available research on opinion spam identification using machine learning and natural language processing for this study. The goal of this research was to get a better understanding of existing research on methods and machine learning approaches that have been employed in the past, as well as to give future insights to researchers. Future work on this project would be trying to diversify our training data. This would hopefully allow us to make models that would perform well on any form of opinion spam and give a better model overall. We could also look into generating more features with some more domain knowledge about linguistic data.\n",
    "\n",
    "Because websites like Yelp and Dianping have built-in filters that detect fraudulent reviews flawlessly, data from these platforms can be useful in developing an accurate model for detecting opinion spam. Because manually identifying real-world spam is difficult, if not impossible, teaching AI to learn from human-written evaluations and generate comparable reviews is one technique to create a dataset that reflects real-time opinion spam. For the categorization of false reviews, the focus might be on training neural networks and deep neural networks. Even while some machine learning algorithms outperform neural networks on smaller data sets, neural networks will become increasingly important in the categorization of such large amounts of data as views on websites grow."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TCSS535_435ProjectPartB.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
